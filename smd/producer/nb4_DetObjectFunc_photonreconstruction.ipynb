{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a24571-0732-4151-89c2-f1ac44bd6e9f",
   "metadata": {},
   "source": [
    "## Functions to dropletize/photonize (sparse) data\n",
    "\n",
    "This notebook demonstrates how to treat sparse datasets.\n",
    "We will start by plotting the data after applying a threshold and make a 'pixelhistogram' (the spectrum of the data in each of the pixels). \n",
    "Once can see the single photon peak with a large shoulder on the left side due to cases where the photon deposited energy in neighboring pixels.\n",
    "\n",
    "We then show how the dropletize this data and plot the spectrum of the 'droplets' - in this log-plot we can clearly see single & multiple photons. There are no signs\n",
    "photons of a different energy. This confirms that we can use one of two photon reconstruction algorithms.\n",
    "\n",
    "Please note that this detector has _not_ been converted to keV. For all runs since run 19, all detectors, including the epix100 report their energies in keV!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c740cc74-c098-4584-a056-49cfe0fd14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "from tqdm import tqdm\n",
    "import h5py as h5\n",
    "from pathlib import Path\n",
    "import tables\n",
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "import psana as ps\n",
    "sys.path.append('/sdf/group/lcls/ds/tools/smalldata_tools/latest')\n",
    "from smalldata_tools.DetObject import DetObject, DetObjectFunc\n",
    "from smalldata_tools.ana_funcs.roi_rebin import spectrumFunc\n",
    "from smalldata_tools.ana_funcs.sparsifyFunc import sparsifyFunc#, unsparsifyFunc\n",
    "\n",
    "from smalldata_tools.SmallDataUtils import setParameter, getUserData, getUserEnvData\n",
    "\n",
    "from smalldata_tools.utilities_plotting import hv_image_ctl\n",
    "from smalldata_tools.utilities_plotting import hv_image\n",
    "from smalldata_tools.utilities import image_from_dxy\n",
    "from smalldata_tools.utilities import unsparsify\n",
    "\n",
    "run = 630 \n",
    "exp = 'xpptut15'\n",
    "\n",
    "dsname = 'exp={}:run={}'.format(exp,run,exp[:3],exp)\n",
    "\n",
    "ds = ps.MPIDataSource(dsname)\n",
    "#ds.detnames()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4810f-30bc-491b-bb3a-23a3f4b58c03",
   "metadata": {},
   "source": [
    "# Set detObject and ana function\n",
    "\n",
    "This is where the detector and the analysis function are defined. Here we specify a 'spectrumFunc' which will make the 'pixelhistogram'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76497dd8-09f6-4e91-b471-93469a07ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "detname = 'epix_alc1' #epix100 w/ beamstop\n",
    "photE=166.\n",
    "det = DetObject(detname, ds.env(), int(run)) #epix100 w/ beamstop\n",
    "\n",
    "#plot the pixel histogram\n",
    "func1_dict = {}\n",
    "func1_dict['bins'] = np.arange(-1.5,photE*2.5,photE/100).tolist()\n",
    "func1 = spectrumFunc(**func1_dict)\n",
    "\n",
    "# add function to detector pipeline\n",
    "det.addFunc(func1)\n",
    "\n",
    "userDataCfg = det.params_as_dict()\n",
    "\n",
    "max_evt = 1\n",
    "ds.break_after(max_evt) # stop iteration after max_evt events (break statements do not work reliably with MPIDataSource).\n",
    "\n",
    "userDict = {}\n",
    "for nevt,evt in tqdm(enumerate(ds.events())):        \n",
    "    det.getData(evt)\n",
    "    det.processFuncs()\n",
    "    userDict[det._name]=getUserData(det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab824de1",
   "metadata": {},
   "source": [
    "## Plot detector data of the last event\n",
    "\n",
    "We deploy a low threshold, largely to keep the color scale in a good range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "det_evt_thres = det.evt.dat.copy()\n",
    "thresADU = -99.5\n",
    "det_evt_thres[det.evt.dat<thresADU]=0 \n",
    "#hv_image_ctl(image_from_dxy(det_evt_thres,userDataCfg['ix'],userDataCfg['iy']))\n",
    "hv_image(image_from_dxy(det_evt_thres,userDataCfg['ix'],userDataCfg['iy']), \\\n",
    "         imgLow=-10.5, imgHigh=photE*1.5, cmap='rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1c050",
   "metadata": {},
   "source": [
    "## Plot the pixel histogram "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0662f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = hv.Points( (0.5*(userDataCfg['spectrum__spectrum_bins'][:-1]+userDataCfg['spectrum__spectrum_bins'][1:]),\\\n",
    "    np.log(userDict[detname]['spectrum_histogram'])), \\\n",
    "          [('ADU','ADU'),('npix','npix')]).options(width=800)\n",
    "for i in range(3):\n",
    "    plot *= hv.VLine(photE*(i+1)).options(line_dash='dotted', color='red')\n",
    "plot                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a65553",
   "metadata": {},
   "source": [
    "## Dropletize the data & look at spectrum\n",
    "\n",
    "We are finding droplets which is a sets of pixels sharing a boundary above threshold. Pixels sharing an edge with these pixels that fall above a optional second, lower threshold are added - this sharpens the spectrum, but can lead to merged photons should the second threshold be too low. 'thresADU' means that only droplets with a summed energy above the given threshold are kept for further analysis. This is to reject cases where fluctuations have led to pixels above the threshold, but below where we expect to find the photons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d15728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smalldata_tools.ana_funcs.droplet import dropletFunc\n",
    "\n",
    "func2_dict = {}\n",
    "func2_dict['threshold'] = 3.\n",
    "func2_dict['thresholdLow'] = 1.\n",
    "func2_dict['thresADU'] = 4.\n",
    "func2 = dropletFunc(**func2_dict)\n",
    "\n",
    "sfunc2 = sparsifyFunc(nData=15000) \n",
    "func2.addFunc(sfunc2)\n",
    "\n",
    "# add function to detector pipeline\n",
    "det.addFunc(func2)\n",
    "\n",
    "userDataCfg = det.params_as_dict()\n",
    "userDict = {}\n",
    "for nevt,evt in tqdm(enumerate(ds.events())):        \n",
    "    det.getData(evt)\n",
    "    det.processFuncs()\n",
    "    userDict[det._name]=getUserData(det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropletHis = np.histogram(userDict[detname]['droplet_sparse_data'], np.arange(.5,photE*4.5,photE/100))\n",
    "\n",
    "plot = hv.Points( (0.5*(dropletHis[1][:-1]+dropletHis[1][1:]),\\\n",
    "    np.log(dropletHis[0])), \\\n",
    "          [('dropADU','dropADU'),('ndrop','ndrop')]).options(width=800)\n",
    "for i in range(5):\n",
    "    plot *= hv.VLine(photE*(i+1)).options(line_dash='dotted', color='red')\n",
    "    plot *= hv.VLine(photE*i+photE*0.5).options(line_dash='dashed', color='green', line_width=1)\n",
    "    #plot *= hv.VLine(photE*i+11.7).options(line_dash='dotted', color='green', line_width=1)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f197b99",
   "metadata": {},
   "source": [
    "## Make an image with the droplets\n",
    "In the producer file, you would use the unsparsifyFunc and a (full) ROI w. imageFunc if needed. Similarly, you could use the azimuthal averaging code after the unsparsify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f450f56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "droplet_sparse={}\n",
    "droplet_sparse['data'] = userDict[detname]['droplet_sparse_data']\n",
    "droplet_sparse['row'] = userDict[detname]['droplet_sparse_row']\n",
    "droplet_sparse['col'] = userDict[detname]['droplet_sparse_col']\n",
    "droplet_sparse['tile'] = userDict[detname]['droplet_sparse_tile']\n",
    "\n",
    "det_drop = unsparsify(droplet_sparse, shape=userDataCfg['mask'].shape)\n",
    "dropImg = image_from_dxy(det_drop.flatten(), userDataCfg['ix'].flatten(), userDataCfg['iy'].flatten())\n",
    "\n",
    "hv_image_ctl(dropImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f91f3b",
   "metadata": {},
   "source": [
    "# Photonize the data (2 pixel, sum > threshold, LCLS1 only)\n",
    "\n",
    "This algorithm which has only been implemented for LCLS1 defines photons as 1 or two neighboring photons where the energy sum is > 'thr_fraction' of the expected photon energy. It works well in cases where the photons are usually contained in 1 or maybe 2 pixels, but can fail to find photons where a significant fraction of energy is captured in a third pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70355e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smalldata_tools.ana_funcs.photons import photonFunc\n",
    "\n",
    "func3_dict = {}\n",
    "func3_dict['ADU_per_photon'] =photE\n",
    "func3_dict['thr_fraction'] = 0.85\n",
    "func3 = photonFunc(**func3_dict)\n",
    "\n",
    "sfunc3 = sparsifyFunc(nData=15000) \n",
    "func3.addFunc(sfunc3)\n",
    "\n",
    "# add function to detector pipeline\n",
    "det.addFunc(func3)\n",
    "\n",
    "userDataCfg = det.params_as_dict()\n",
    "userDict = {}\n",
    "# small_data = ds.small_data('./pyfai_dev.h5', gather_interval=5)\n",
    "for nevt,evt in tqdm(enumerate(ds.events())):        \n",
    "    det.getData(evt)\n",
    "    det.processFuncs()\n",
    "    userDict[det._name]=getUserData(det)\n",
    "    # small_data.event(userDict)\n",
    "# small_data.close()\n",
    "\n",
    "photon_sparse={}\n",
    "photon_sparse['data'] = userDict[detname]['photon_sparse_data']\n",
    "photon_sparse['row'] = userDict[detname]['photon_sparse_row']\n",
    "photon_sparse['col'] = userDict[detname]['photon_sparse_col']\n",
    "photon_sparse['tile'] = userDict[detname]['photon_sparse_tile']\n",
    "\n",
    "det_phot = unsparsify(photon_sparse, shape=userDataCfg['mask'].shape)\n",
    "photImg = image_from_dxy(det_phot.flatten(), userDataCfg['ix'].flatten(), userDataCfg['iy'].flatten())\n",
    "\n",
    "hv_image_ctl(photImg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0e1860",
   "metadata": {},
   "source": [
    "# Different approach: photonize the droplet output: place photons inside of the droplet\n",
    "This approach place single photons inside of multiphoton droplets. Also here, we assume that 2 pixels share the photon energy, but the last photon will use all the remaining energy, so no threshold for the energy contained in 2 pixels is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d968afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smalldata_tools.ana_funcs.droplet2Photons import droplet2Photons\n",
    "\n",
    "func4_dict = {}\n",
    "func4_dict['photpts'] = (np.arange(1000)-1)*photE + photE/2.\n",
    "func4 = droplet2Photons(**func4_dict)\n",
    "\n",
    "sfunc4 = sparsifyFunc(nData=100000) \n",
    "func4.addFunc(sfunc4)\n",
    "\n",
    "func2_dict = {}\n",
    "func2_dict['threshold'] = 3.\n",
    "func2_dict['thresholdLow'] = 1.\n",
    "func2_dict['thresADU'] = 4.\n",
    "func2 = dropletFunc(**func2_dict)\n",
    "func2.addFunc(func4)\n",
    "\n",
    "detname_d2p = '%s_d2p'%detname\n",
    "det_d2p = DetObject(detname, ds.env(), int(run), name=detname_d2p) #epix100 w/ beamstop\n",
    "# add function to detector pipeline\n",
    "det_d2p.addFunc(func2)\n",
    "\n",
    "userDataCfg_d2p = det_d2p.params_as_dict()\n",
    "userDict_d2p = {}\n",
    "# small_data = ds.small_data('./pyfai_dev.h5', gather_interval=5)\n",
    "for nevt,evt in tqdm(enumerate(ds.events())):        \n",
    "    det_d2p.getData(evt)\n",
    "    det_d2p.processFuncs()\n",
    "    userDict_d2p[det._name]=getUserData(det_d2p)\n",
    "    # small_data.event(userDict)\n",
    "# small_data.close()\n",
    "\n",
    "d2p_sparse={}\n",
    "d2p_sparse['data'] = userDict_d2p[detname]['droplet_droplet2phot_sparse_data']\n",
    "d2p_sparse['row'] = userDict_d2p[detname]['droplet_droplet2phot_sparse_row']\n",
    "d2p_sparse['col'] = userDict_d2p[detname]['droplet_droplet2phot_sparse_col']\n",
    "d2p_sparse['tile'] = userDict_d2p[detname]['droplet_droplet2phot_sparse_tile']\n",
    "\n",
    "det_phot = unsparsify(d2p_sparse, shape=userDataCfg['mask'].shape)\n",
    "photImg = image_from_dxy(det_phot.flatten(), userDataCfg['ix'].flatten(), userDataCfg['iy'].flatten())\n",
    "\n",
    "hv_image_ctl(photImg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
